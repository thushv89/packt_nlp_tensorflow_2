{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe: Global Vectors for Word2Vec\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/packt_nlp_tensorflow_2/blob/master/Ch04-Advance-Word-Vectors/ch4_glove.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "\n",
    "### Downloading the data\n",
    "\n",
    "This code downloads a [BBC dataset](hhttp://mlg.ucd.ie/files/datasets/bbc-fulltext.zip) consisting of news articles published by BBC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "bbc-fulltext.zip has already been extracted\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    \n",
    "    # Create the data directory if not exist\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "    \n",
    "    # If file doesnt exist, download\n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "  \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    \n",
    "    # If data has not been extracted already, extract data\n",
    "    if not os.path.exists(extract_path):        \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    \n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data without Preprocessing \n",
    "\n",
    "Here we read all the files and keep them as a list of strings, where each string is a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 401.txt................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 001.txt\n",
      "Detected 2226 stories\n",
      "865250 words found in the total news set\n",
      "Example words (start):  Consists of 2225 documents from the BBC news websi\n",
      "Example words (end):  Online was the game, ahhhh them was the days ! LOL\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir):\n",
    "    \n",
    "    # This will contain the full list of stories\n",
    "    news_stories = []\n",
    "    \n",
    "    print(\"Reading files\")\n",
    "    \n",
    "    i = 0 # Just used for printing progress\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        \n",
    "        for fi, f in enumerate(files):\n",
    "            \n",
    "            # We don't read the readme file\n",
    "            if 'README' in f:\n",
    "                continue\n",
    "            \n",
    "            # Printing progress\n",
    "            i += 1\n",
    "            print(\".\"*i, f, end='\\r')\n",
    "            \n",
    "            # Open the file\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as f:\n",
    "                \n",
    "                story = []\n",
    "                # Read all the lines\n",
    "                for row in f:\n",
    "                                        \n",
    "                    story.append(row.strip())\n",
    "                    \n",
    "                # Create a single string with all the rows in the doc\n",
    "                story = ' '.join(story)                        \n",
    "                # Add that to the list\n",
    "                news_stories.append(story)  \n",
    "                \n",
    "        print('', end='\\r')\n",
    "        \n",
    "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
    "    return news_stories\n",
    "                \n",
    "  \n",
    "news_stories = read_data(os.path.join('data', 'bbc'))\n",
    "\n",
    "# Printing some stats and sample data\n",
    "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Tokenizer\n",
    "\n",
    "Here we build a tokenizer, that performs simple preprocessing like,\n",
    "\n",
    "* Converting letters to lower case\n",
    "* Removing punctuation\n",
    "\n",
    "and tokenize the strings based on a defined separator. Then each token is converted to an Integer ID, as computers understand numbers, not strings. In the background, the tokenizer builds a word to index dictionary, that defines a unique ID for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 15000 + 1\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=n_vocab - 1,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token=''\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the word co-occurrence matrix\n",
    "\n",
    "Why GloVe shine above context window based method is that it employs global statistics of the corpus in to the model (according to authors). This is done by using information from the word co-occurance matrix to optimize the word vectors. Basically, the $X(i,j)$ entry of the co-occurance matrix says how frequent word $i$ to appear near $j$. \n",
    "\n",
    "We also use an optional weighting mechanishm to give more weight to words close together than to the ones further-apart (from experiments section of the paper).\n",
    "\n",
    "**Note**: When generating the matrix for the first time, it will take a significant amount of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................... 2200/2226\n",
      "\n",
      "It took 300.5993404388428 seconds to generate the co-occurrence matrix\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import save_npz, load_npz\n",
    "\n",
    "def generate_cooc_matrix(text, tokenizer, window_size, n_vocab, use_weighting=True):\n",
    "    \n",
    "    # Convert list of text to list of list of word IDs\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    \n",
    "    # A sparse matrix to retain co-occurrences of words\n",
    "    cooc_mat = lil_matrix((n_vocab, n_vocab), dtype=np.float32)\n",
    "    \n",
    "    # Go through each sequence one by one\n",
    "    for si, sequence in enumerate(sequences):\n",
    "        \n",
    "        # Printing the progress\n",
    "        if (si+1)%100==0:\n",
    "            print('.'*((si+1)//100), f\"{si+1}/{len(sequences)}\", end='\\r')\n",
    "        \n",
    "        # For each target word,\n",
    "        for i, wi in zip(np.arange(window_size, len(sequence)-window_size), sequence[window_size:-window_size]):\n",
    "            \n",
    "            # Get the context window word IDs\n",
    "            context_window = sequence[i-window_size: i+window_size+1]            \n",
    "            \n",
    "            # The weight for the words in the context window (except target word) will be 1\n",
    "            window_weights = np.ones(shape=(window_size*2 + 1,), dtype=np.float32)\n",
    "            window_weights[window_size] = 0.0\n",
    "\n",
    "            if use_weighting:\n",
    "                # If weighting is used, penalize context words based on distance to target word\n",
    "                distances = np.abs(np.arange(-window_size, window_size+1))\n",
    "                distances[window_size] = 1.0\n",
    "                # Update the sparse matrix\n",
    "                cooc_mat[wi, context_window] += window_weights/distances\n",
    "            else:\n",
    "                # Update the sparse matrix\n",
    "                cooc_mat[wi, context_window] += window_weights\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return cooc_mat    \n",
    "\n",
    "# ----------------------------------------- IMPORTANT ---------------------------------------------- #\n",
    "#                                                                                                    #\n",
    "# Set this true or false, depending on whether you want to generate the matrix or reuse the existing #\n",
    "#                                                                                                    #\n",
    "# ---------------------------------------------------------------------------------------------------#\n",
    "generate_cooc = False\n",
    "\n",
    "# Generate the matrix\n",
    "if generate_cooc:\n",
    "    t1 = time.time()\n",
    "    cooc_mat = generate_cooc_matrix(news_stories, tokenizer, 1, n_vocab, True)\n",
    "    t2 = time.time()\n",
    "    print(f\"It took {t2-t1} seconds to generate the co-occurrence matrix\")\n",
    "    \n",
    "    save_npz(os.path.join('data','cooc_mat.npz'), cooc_mat.tocsr())\n",
    "# Load the matrix from disk\n",
    "else:\n",
    "    try:\n",
    "        cooc_mat = load_npz(os.path.join('data','cooc_mat.npz')).tolil()\n",
    "        print(f\"Cooc matrix of type {type(cooc_mat).__name__} was loaded from disk\")\n",
    "    except FileNotFoundError as ex:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the co-occurrence matrix on the disk. Did you generate the matrix by setting generate_cooc=True?\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the validity of the co-occurrence matrix\n",
    "\n",
    "Here we will see if the context around a given word has sensible words appearing in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x22267584548>,\n",
       "  <matplotlib.axis.XTick at 0x22267584088>,\n",
       "  <matplotlib.axis.XTick at 0x221cedfff08>,\n",
       "  <matplotlib.axis.XTick at 0x2226759f2c8>,\n",
       "  <matplotlib.axis.XTick at 0x2226759f348>,\n",
       "  <matplotlib.axis.XTick at 0x2226758d108>,\n",
       "  <matplotlib.axis.XTick at 0x222675a0988>,\n",
       "  <matplotlib.axis.XTick at 0x222675a0188>,\n",
       "  <matplotlib.axis.XTick at 0x222675ce048>,\n",
       "  <matplotlib.axis.XTick at 0x222675ce348>,\n",
       "  <matplotlib.axis.XTick at 0x222675c1a48>,\n",
       "  <matplotlib.axis.XTick at 0x2226759db88>,\n",
       "  <matplotlib.axis.XTick at 0x222675ce408>,\n",
       "  <matplotlib.axis.XTick at 0x2226758dfc8>,\n",
       "  <matplotlib.axis.XTick at 0x22267591908>,\n",
       "  <matplotlib.axis.XTick at 0x222675a47c8>,\n",
       "  <matplotlib.axis.XTick at 0x222675a4588>,\n",
       "  <matplotlib.axis.XTick at 0x222675bfb08>,\n",
       "  <matplotlib.axis.XTick at 0x222675af888>,\n",
       "  <matplotlib.axis.XTick at 0x222675a73c8>,\n",
       "  <matplotlib.axis.XTick at 0x222675aefc8>,\n",
       "  <matplotlib.axis.XTick at 0x222675a98c8>,\n",
       "  <matplotlib.axis.XTick at 0x222675aee88>,\n",
       "  <matplotlib.axis.XTick at 0x222675a41c8>,\n",
       "  <matplotlib.axis.XTick at 0x222675cfb08>],\n",
       " [Text(0, 0, 'pundit'),\n",
       "  Text(0, 0, 'she'),\n",
       "  Text(0, 0, \"we've\"),\n",
       "  Text(0, 0, 'it'),\n",
       "  Text(0, 0, 'he'),\n",
       "  Text(0, 0, 'i'),\n",
       "  Text(0, 0, 'understands'),\n",
       "  Text(0, 0, 'cas'),\n",
       "  Text(0, 0, 'said'),\n",
       "  Text(0, 0, 'website'),\n",
       "  Text(0, 0, 'we'),\n",
       "  Text(0, 0, 'a'),\n",
       "  Text(0, 0, 'is'),\n",
       "  Text(0, 0, \"it's\"),\n",
       "  Text(0, 0, 'on'),\n",
       "  Text(0, 0, 'school'),\n",
       "  Text(0, 0, 'wales'),\n",
       "  Text(0, 0, 'that'),\n",
       "  Text(0, 0, 'of'),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, 'in'),\n",
       "  Text(0, 0, 'and'),\n",
       "  Text(0, 0, 'for'),\n",
       "  Text(0, 0, 'the'),\n",
       "  Text(0, 0, 'bbc')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "word = 'sport'\n",
    "assert word in tokenizer.word_index, f\"Word {word} is not in the tokenizer\"\n",
    "assert tokenizer.word_index[word] <= n_vocab, f\"The word {word} is an out of vocabuary word. Please try something else\"\n",
    "\n",
    "# Get the vector of co-occurrences for a given word \n",
    "cooc_vec = np.array(cooc_mat.getrow(tokenizer.word_index[word]).todense()).ravel()\n",
    "# Get indices of words with maximum value\n",
    "max_ind = np.argsort(cooc_vec)[-25:]\n",
    "\n",
    "# Plot the words and values\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(np.arange(0, 25), cooc_vec[max_ind])\n",
    "plt.xticks(ticks=np.arange(0, 25), labels=[tokenizer.index_word[i] for i in max_ind], rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defining Hyperparameters\n",
    "\n",
    "Here we define several hyperparameters including `batch_size` (amount of samples in a single batch) `embedding_size` (size of embedding vectors) `window_size` (context window size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096 # Data points in a single batch\n",
    "\n",
    "embedding_size = 128 # Dimension of the embedding vector.\n",
    "\n",
    "window_size=1 # We use a window size of 1 on either side of target word\n",
    "\n",
    "epochs = 5 # Number of epochs to train for\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors\n",
    "valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "# We sample valid datapoints randomly from a large window without always being deterministic\n",
    "valid_window = 250\n",
    "\n",
    "# When selecting valid examples, we select some of the most frequent words as well as\n",
    "# some moderately rare words as well\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "valid_term_ids = np.array(random.sample(range(valid_window), valid_size))\n",
    "valid_term_ids = np.append(\n",
    "    valid_term_ids, random.sample(range(1000, 1000+valid_window), valid_size),\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model Computations\n",
    "\n",
    "The model takes two inputs,\n",
    "\n",
    "* A (batch of) context word ID(s) - $i$\n",
    "* A (batch of) target word ID(s) - $j$\n",
    "\n",
    "and computes the following output,\n",
    "\n",
    "$w_i.\\tilde{w}_j + b_i + \\tilde{b}_j$\n",
    "\n",
    "where, $w_i$ is the context embeddings for the words in $i$, $\\tilde{w}_j$ is target embeddings for the words in $j$, $b_i$ and $\\tilde{b}_j$ are two separate biases for context and target spaces. Then the following loss function is used,\n",
    "\n",
    "$J = f(X_{ij}) \\sum_{i,j=1}^{V} (w_i\\tilde{w}_j + b_i + \\tilde{b}_j - log(X_{ij})^2$\n",
    "\n",
    "Here, X_{ij} is the value at (i,j) position in the co-occurrence matrix and f(X_{ij}) is a simple weighting function of X_{ij}. You can see that the loss function looks of the format,\n",
    "\n",
    "$J = A ( B - C ) ^ 2 $\n",
    "\n",
    "Therefore, we will use the mean-squared-error loss and feed in $f(X_{ij})$ values as sample weights during training.\n",
    "\n",
    "---\n",
    "*The behavior of the GloVe word vectors*\n",
    "\n",
    "![The behavior of the GloVe word vectors](notebook_images/04_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glove_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " target_embedding (Embedding)   (None, 128)          1920128     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " context_embedding (Embedding)  (None, 128)          1920128     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['target_embedding[0][0]',       \n",
      "                                                                  'context_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " target_embedding_bias (Embeddi  (None, 1)           15001       ['input_1[0][0]']                \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " context_embedding_bias (Embedd  (None, 1)           15001       ['input_2[0][0]']                \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1)            0           ['dot[0][0]',                    \n",
      "                                                                  'target_embedding_bias[0][0]',  \n",
      "                                                                  'context_embedding_bias[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,870,258\n",
      "Trainable params: 3,870,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Define two input layers for context and target words\n",
    "word_i = Input(shape=())\n",
    "word_j = Input(shape=())\n",
    "\n",
    "# Each context and target has their own embeddings (weights and biases)\n",
    "\n",
    "# Embedding weights\n",
    "embeddings_i = Embedding(n_vocab, embedding_size, name='target_embedding')(word_i)\n",
    "embeddings_j = Embedding(n_vocab, embedding_size, name='context_embedding')(word_j)\n",
    "\n",
    "# Embedding biases\n",
    "b_i = Embedding(n_vocab, 1, name='target_embedding_bias')(word_i)    \n",
    "b_j = Embedding(n_vocab, 1, name='context_embedding_bias')(word_j)\n",
    "\n",
    "# Compute the dot product between embedding vectors (i.e. w_i.w_j)\n",
    "ij_dot = Dot(axes=-1)([embeddings_i,embeddings_j])\n",
    "\n",
    "# Add the biases (i.e. w_i.w_j + b_i + b_j )\n",
    "pred = Add()([ij_dot, b_i, b_j])\n",
    "\n",
    "# The final model\n",
    "glove_model = Model(inputs=[word_i, word_j],outputs=pred, name='glove_model')\n",
    "\n",
    "# Glove has a specific loss function with a sound mathematical underpinning\n",
    "# It is a form of mean squared error\n",
    "glove_model.compile(loss=\"mse\", optimizer = 'adam')\n",
    "\n",
    "glove_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for GloVe model\n",
    "\n",
    "The Glove model we implemented, \n",
    "\n",
    "* Takes two inputs; context words and target words \n",
    "* Computes the mean squared error as, $(\\hat{y}_{ij} - log(X_{ij}))^2$ for the model output $\\hat{y}_{ij}$\n",
    "* Use sample weights returned by $f(X_{ij})$\n",
    "\n",
    "Therefore, in the data generator we return a tuple of,\n",
    "\n",
    "`(inputs, targets, sample weights)`\n",
    "\n",
    "which translates to,\n",
    "\n",
    "`((batch of target words, batch or context words), batch of log(X_{ij}), batch of f(X_{ij})`                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sequences = tokenizer.texts_to_sequences(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 9023,  9334,  2214,   694,  6336,   427,  3838,  6820, 11590,\n",
      "        4310]), array([ 9334,  9986,   105,   427,  6345, 10358,     2,     2,  3763,\n",
      "        2713]))\n",
      "[0.6931472 0.        0.6931472 0.        2.3025851 1.7917595 2.7725887\n",
      " 0.        0.6931472 1.0986123]\n",
      "[0.03162277 0.         0.03162277 0.         0.16431677 0.10573713\n",
      " 0.24102853 0.         0.03162277 0.05318296]\n"
     ]
    }
   ],
   "source": [
    "def glove_data_generator(\n",
    "    sequences, window_size, batch_size, vocab_size, cooccurrence_matrix, x_max=100.0, alpha=0.75, seed=None\n",
    "):\n",
    "    \"\"\" Generate batches of inputs and targets for GloVe \"\"\"\n",
    "    \n",
    "    # Shuffle the data so that, every epoch, the order of data is different\n",
    "    rand_sequence_ids = np.arange(len(sequences))                    \n",
    "    np.random.shuffle(rand_sequence_ids)\n",
    "\n",
    "    # We will use a sampling table to make sure, we don't oversample stopwords\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "    \n",
    "    # For each story/article\n",
    "    for si in rand_sequence_ids:\n",
    "        \n",
    "        # Generate positive skip-grams while using sub-sampling \n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequences[si], \n",
    "            vocabulary_size=vocab_size, \n",
    "            window_size=window_size, \n",
    "            negative_samples=0.0, \n",
    "            shuffle=False,   \n",
    "            sampling_table=sampling_table,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        # Take targets and context words separately\n",
    "        targets, context = zip(*positive_skip_grams)\n",
    "        targets, context = np.array(targets).ravel(), np.array(context).ravel()\n",
    "        \n",
    "        \n",
    "        x_ij = np.array(cooccurrence_matrix[targets, context].toarray()).ravel()\n",
    "        \n",
    "        # Compute log - Introducing an additive shift to make sure we don't compute log(0)\n",
    "        log_x_ij = np.log(x_ij + 1)\n",
    "        \n",
    "        # Sample weights \n",
    "        # if x < x_max => (x/x_max)**alpha / else => 1        \n",
    "        sample_weights = np.where(x_ij < x_max, (x_ij/x_max)**alpha, 1)\n",
    "        \n",
    "        # If seed is not provided generate a random one\n",
    "        if not seed:\n",
    "            seed = random.randint(0, 10e6)\n",
    "        \n",
    "        # Shuffle data\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(context)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(targets)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(log_x_ij)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(sample_weights)\n",
    "        \n",
    "        # Generate a batch or data in the format \n",
    "        # ((target words, context words), log(X_ij) <- true targets, f(X_ij) <- sample weights)\n",
    "        for eg_id_start in range(0, context.shape[0], batch_size):            \n",
    "            yield (\n",
    "                targets[eg_id_start: min(eg_id_start+batch_size, targets.shape[0])], \n",
    "                context[eg_id_start: min(eg_id_start+batch_size, context.shape[0])]\n",
    "            ), log_x_ij[eg_id_start: min(eg_id_start+batch_size, x_ij.shape[0])], \\\n",
    "            sample_weights[eg_id_start: min(eg_id_start+batch_size, sample_weights.shape[0])]\n",
    "\n",
    "\n",
    "# Generate some data\n",
    "news_glove_data_gen = glove_data_generator(\n",
    "    news_sequences, 2, 10, n_vocab, cooc_mat\n",
    ")\n",
    "\n",
    "for x, y, z in news_glove_data_gen:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Here we train the GloVe model we defined above. We train for `epochs` and at the end of each epoch, we compute word similarities on a set of chosen validation words (`valid_term_ids`). Similar to in Chapter 3, we use a Keras callback to compute the most similar words.\n",
    "\n",
    "### Calculating Word Similarities\n",
    "\n",
    "We calculate the similarity between two given words in terms of the cosine distance. To do this efficiently we use matrix operations to do so, as shown below. Furthermore, we define the computations as a callback, which will automatically run at the end of an epoch during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_term_ids, model_with_embeddings, tokenizer):\n",
    "        \n",
    "        self.valid_term_ids = valid_term_ids\n",
    "        self.model_with_embeddings = model_with_embeddings\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" Validation logic \"\"\"\n",
    "                \n",
    "        # We will use context embeddings to get the most similar words\n",
    "        # Other strategies include: using target embeddings, mean embeddings after avaraging context/target\n",
    "        embedding_weights = self.model_with_embeddings.get_layer(\"context_embedding\").get_weights()[0]\n",
    "        normalized_embeddings = embedding_weights / np.sqrt(np.sum(embedding_weights**2, axis=1, keepdims=True))\n",
    "        \n",
    "        # Get the embeddings corresponding to valid_term_ids\n",
    "        valid_embeddings = normalized_embeddings[self.valid_term_ids, :]\n",
    "        \n",
    "        # Compute the similarity between valid_term_ids and all the embeddings\n",
    "        # V x d (d x D) => V x D\n",
    "        top_k = 5 # Top k items will be displayed\n",
    "        similarity = np.dot(valid_embeddings, normalized_embeddings.T)\n",
    "        \n",
    "        # Invert similarity matrix to negative\n",
    "        # Ignore the first one because that would be the same word as the probe word\n",
    "        similarity_top_k = np.argsort(-similarity, axis=1)[:, 1: top_k+1]\n",
    "                \n",
    "        # Print the output\n",
    "        for i, term_id in enumerate(valid_term_ids):\n",
    "            \n",
    "            similar_word_str = ', '.join([self.tokenizer.index_word[j] for j in similarity_top_k[i, :] if j > 1])\n",
    "            print(f\"{self.tokenizer.index_word[term_id]}: {similar_word_str}\")\n",
    "        \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 started\n",
      "      4/Unknown - 1s 65ms/step - loss: 1.9839WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.0244s). Check your callbacks.\n",
      "   2220/Unknown - 11s 5ms/step - loss: 0.6069election: attorney, forthcoming, motors, us, countries\n",
      "me: easy, being, set, many, which\n",
      "with: hold, uncertainties, press, together, reservoir\n",
      "you: we, they, now, like, it's\n",
      "were: are, when, but, say, do\n",
      "win: or, jobs, one, yukos, go\n",
      "those: took, women, won, some\n",
      "music: media, yukos, content, games, came\n",
      "also: never, it, now, who, they\n",
      "third: second, number, one, great, strong\n",
      "best: category, one, british, prize, award\n",
      "him: game, many, england, set, one\n",
      "too: very, great, bid, how, get\n",
      "some: one, because, media, many\n",
      "through: get, full, net, almost, personal\n",
      "mr: tony, book, resignation, charles, malcolm\n",
      "file: 350, rendered, liberalisation, justification, scene's\n",
      "pair: easy, ministers, very, clear, being\n",
      "ceremony: time, its, fast, us, or\n",
      "believed: said, added, was, says, if\n",
      "post: one, go, game, run, present\n",
      "indian: england, games, pro, round, his\n",
      "successful: companies, jobs, or, claiming\n",
      "care: and, while, third, but, claiming\n",
      "russia: shown, predicted, won, england\n",
      "talk: media, yukos, one, way\n",
      "programs: the, his, england, came, largest\n",
      "fair: came, without, one, many, main\n",
      "hollywood: jewish, mgm, becomes, mp, serve\n",
      "attempt: made, easy, giving, it's, set\n",
      "leave: failed, decided, buy, singer's, 21\n",
      "light: adaptation, came, the, near, sunday's\n",
      "\n",
      "\n",
      "2226/2226 [==============================] - 11s 5ms/step - loss: 0.6051\n",
      "Epoch: 2/5 started\n",
      "   2222/Unknown - 10s 4ms/step - loss: 0.0371election: attorney, forthcoming, posters, motors, snap\n",
      "me: part, thing, many, put, easy\n",
      "with: reservoir, hold, accession, honoured, together\n",
      "you: we, like, they, she, concerned\n",
      "were: are, say, whom, wasn't, when\n",
      "win: look, work, support, end, go\n",
      "those: won, took, immigration, because, tight\n",
      "music: media, formats, end, present, head\n",
      "also: never, doing, given, now, which\n",
      "third: fourth, second, number, effort, great\n",
      "best: supporting, category, original, managing, care\n",
      "him: part, role, deal, look, compete\n",
      "too: larger, how, common, very, taking\n",
      "some: because, average, number, saying, affected\n",
      "through: full, reconstruction, get, learning, ahead\n",
      "mr: 63, malcolm, article, resignation, bernie\n",
      "file: illegally, systems, networks, songs, 350\n",
      "pair: immigration, me, named, moved, easy\n",
      "ceremony: empire, risk, nominations, compared, january\n",
      "believed: added, said, says, believes, when\n",
      "post: present, transport, run, go, pay\n",
      "indian: pro, england, course, end, aware\n",
      "successful: offer, granted, named, relationship, course\n",
      "care: lot, support, number, survey, fight\n",
      "russia: january, head, europe, predicted, role\n",
      "talk: part, case, end, look, role\n",
      "programs: tie, shadow, the, leaders, tennis\n",
      "fair: came, compared, japan, important, pension\n",
      "hollywood: mgm, jewish, movie, lovers, exchanges\n",
      "attempt: easy, made, fight, lead, play\n",
      "leave: pay, buy, reach, failed, according\n",
      "light: amplify, continuous, leaders, based, near\n",
      "\n",
      "\n",
      "2226/2226 [==============================] - 10s 5ms/step - loss: 0.0370\n",
      "Epoch: 3/5 started\n",
      "   2217/Unknown - 10s 4ms/step - loss: 0.0161election: attorney, forthcoming, posters, november's, empt\n",
      "me: part, deal, compete, kind, course\n",
      "with: reservoir, accession, together, honoured, hold\n",
      "you: god, we, goodness, you're, they\n",
      "were: are, say, feel, when, if\n",
      "win: series, appear, look, uk's, compete\n",
      "those: supported, won, women, died, paterson\n",
      "music: cameras, subscriber, revolution, legitimate, unlimited\n",
      "also: given, never, thought, become, going\n",
      "third: fourth, second, effort, huckabees, long\n",
      "best: category, supporting, care, 7m, managing\n",
      "him: part, me, compete, look, risk\n",
      "too: larger, how, pretty, bigger, common\n",
      "some: because, ukip, number, average, affected\n",
      "through: ahead, reconstruction, around, full, row\n",
      "mr: 63, bernie, malcolm, cherie, article\n",
      "file: systems, illegally, networks, rewards, drama\n",
      "pair: storm, turned, won, thousands, around\n",
      "ceremony: empire, role, series, particular, result\n",
      "believed: added, said, says, insisted, believes\n",
      "post: iraq, bidding, phonographic, present, clash\n",
      "indian: apart, pro, end, wales, course\n",
      "successful: relationship, course, pundits, offer, commissioned\n",
      "care: lot, supporting, sense, support, series\n",
      "russia: 2002, january, favour, 2000, 2010\n",
      "talk: talking, part, end, worried, case\n",
      "programs: deficits, independence, logs, hackers, parliament\n",
      "fair: compared, 2002, january, shortly, along\n",
      "hollywood: mgm, jewish, delhi, disney, promised\n",
      "attempt: easy, increase, lead, lot, move\n",
      "leave: pay, according, buy, reach, turn\n",
      "light: amplify, bridges, unveils, continuous, lucent\n",
      "\n",
      "\n",
      "2226/2226 [==============================] - 10s 5ms/step - loss: 0.0161\n",
      "Epoch: 4/5 started\n",
      "   2222/Unknown - 10s 4ms/step - loss: 0.0116election: attorney, forthcoming, empt, posters, motors\n",
      "me: granted, yougov, course, came, part\n",
      "with: reservoir, accession, honoured, supposed, together\n",
      "you: goodness, disguise, god, we, they\n",
      "were: are, say, wasn't, feel, was\n",
      "win: appear, wait, return, buy, beginning\n",
      "those: individuals, mccaughrean, won, died, women\n",
      "music: cameras, divide, revolution, subscriber, assistants\n",
      "also: given, never, announce, become, might\n",
      "third: fourth, second, huckabees, vast, short\n",
      "best: supporting, category, 7m, counterparts, care\n",
      "him: interact, me, used, donors, host\n",
      "too: happier, larger, how, pretty, bigger\n",
      "some: because, lot, fact, couple, years'\n",
      "through: dissolve, ahead, row, comments, dancing\n",
      "mr: 63, bernie, malcolm, hughes, mikhail\n",
      "file: systems, illegally, cocoa, edonkey, consulates\n",
      "pair: fact, storm, uk's, case, thousands\n",
      "ceremony: empire, result, focus, explorer, lot\n",
      "believed: added, said, also, says, portability\n",
      "post: bidding, iraq, potential, shuffle, walkman\n",
      "indian: terms, apart, wales, course, end\n",
      "successful: popular, beneficial, enthusiastic, benefited, course\n",
      "care: lot, orange, microphone, series, sense\n",
      "russia: australia, 2002, sense, october, prince's\n",
      "talk: worried, talking, talked, millions, end\n",
      "programs: laboratories, independence, hackers, deficits, logs\n",
      "fair: kits, ebbers', sort, carry, radicati\n",
      "hollywood: mgm, jewish, promised, day's, movie\n",
      "attempt: easy, lead, increase, lot, unlikely\n",
      "leave: pay, according, buy, reach, turn\n",
      "light: bridges, amplify, continuous, unveils, lucent\n",
      "\n",
      "\n",
      "2226/2226 [==============================] - 10s 5ms/step - loss: 0.0116\n",
      "Epoch: 5/5 started\n",
      "   2217/Unknown - 10s 4ms/step - loss: 0.0095election: attorney, empt, forthcoming, posters, november's\n",
      "me: incorporated, extent, granted, the, translated\n",
      "with: reservoir, supposed, accession, honoured, relaxation\n",
      "you: goodness, we, god, afford, disguise\n",
      "were: are, say, does, mori, ellen\n",
      "win: appear, turn, stay, wait, order\n",
      "those: mccaughrean, won, lawmakers, 150, paterson\n",
      "music: divide, cameras, bpi, revolution, subscriber\n",
      "also: confirmed, given, might, presumably, announce\n",
      "third: fourth, second, short, decade, close\n",
      "best: supporting, category, counterparts, heirs, 7m\n",
      "him: interact, dealt, compete, recovering, involved\n",
      "too: better, pretty, larger, how, anticipated\n",
      "some: gartner, because, sort, years', couple\n",
      "through: dissolve, bookings, ahead, to, comments\n",
      "mr: bernie, malcolm, tony, approaches, 63\n",
      "file: systems, illegally, bottom, consulates, vhs\n",
      "pair: storm, possibility, thousands, fact, resident\n",
      "ceremony: empire, focus, compete, explorer, role\n",
      "believed: added, said, says, insisted, portability\n",
      "post: bidding, iraq, melbourne, merry, potential\n",
      "indian: sues, passenger, apart, end, correction\n",
      "successful: popular, pundits, beneficial, snp, host\n",
      "care: bests, gutsy, famed, literacy, disillusioned\n",
      "russia: sort, kind, sense, favour, couple\n",
      "talk: talking, worried, talked, end, phonographic\n",
      "programs: hackers, laboratories, program, cynical, deficits\n",
      "fair: sort, carry, recognition, kits, chopped\n",
      "hollywood: mgm, day's, jewish, delhi, disney\n",
      "attempt: easy, lead, average, lot, move\n",
      "leave: pay, buy, according, turn, reach\n",
      "light: bridges, amplify, unveils, lucent, rijkaard\n",
      "\n",
      "\n",
      "2226/2226 [==============================] - 10s 5ms/step - loss: 0.0095\n"
     ]
    }
   ],
   "source": [
    "glove_validation_callback = ValidationCallback(valid_term_ids, glove_model, tokenizer)\n",
    "\n",
    "# Train the model for several epochs\n",
    "for ei in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch: {ei+1}/{epochs} started\")\n",
    "    \n",
    "    news_glove_data_gen = glove_data_generator(\n",
    "        news_sequences, window_size, batch_size, n_vocab, cooc_mat\n",
    "    )\n",
    "    \n",
    "    glove_model.fit(\n",
    "        news_glove_data_gen, epochs=1, \n",
    "        callbacks=glove_validation_callback,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the embeddings\n",
    "We save the learned embeddings to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(model, tokenizer, vocab_size, save_dir):\n",
    "    \n",
    "    # Create the directory if doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Get the words sorted according to their ID from the tokenizer\n",
    "    _, words_sorted = zip(*sorted(list(tokenizer.index_word.items()), key=lambda x: x[0])[:vocab_size-1])\n",
    "    # Add one word in front to represent the reserved ID (0)\n",
    "    words_sorted = [None] + list(words_sorted)\n",
    "    \n",
    "    # Create a new array by concatenating embeddings and bias\n",
    "    \n",
    "    context_embedding_weights = model.get_layer(\"context_embedding\").get_weights()[0]\n",
    "    context_embedding_bias = model.get_layer(\"context_embedding_bias\").get_weights()[0]\n",
    "    context_embedding = np.concatenate([context_embedding_weights, context_embedding_bias], axis=1)\n",
    "    \n",
    "    target_embedding_weights = model.get_layer(\"target_embedding\").get_weights()[0]\n",
    "    target_embedding_bias = model.get_layer(\"target_embedding_bias\").get_weights()[0]\n",
    "    target_embedding = np.concatenate([target_embedding_weights, target_embedding_bias], axis=1)\n",
    "    \n",
    "    # Save the array as a Pandas DataFrames\n",
    "    pd.DataFrame(\n",
    "        context_embedding, \n",
    "        index = words_sorted\n",
    "    ).to_pickle(os.path.join(save_dir, \"context_embedding_and_bias.pkl\"))\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        target_embedding, \n",
    "        index = words_sorted\n",
    "    ).to_pickle(os.path.join(save_dir, \"target_embedding_and_bias.pkl\"))\n",
    "\n",
    "    \n",
    "save_embeddings(glove_model, tokenizer, n_vocab, save_dir='glove_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
