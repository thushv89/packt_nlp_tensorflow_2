{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Word Embeddings on the Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "from tensorboard.plugins import projector\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the GloVe file\n",
    "\n",
    "Here we first need to download the GloVe word embeddings (`glove.6B.zip`) found at this [website](https://nlp.stanford.edu/projects/glove/). Then we read the GloVe file to get the first 50000 words in the file. We will be using 50 dimensional word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>-0.41242</td>\n",
       "      <td>0.121700</td>\n",
       "      <td>0.345270</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>-0.49688</td>\n",
       "      <td>-0.178620</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.656600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298710</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>-0.347580</td>\n",
       "      <td>-0.045637</td>\n",
       "      <td>-0.442510</td>\n",
       "      <td>0.187850</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>-0.184110</td>\n",
       "      <td>-0.115140</td>\n",
       "      <td>-0.785810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.236820</td>\n",
       "      <td>-0.16899</td>\n",
       "      <td>0.409510</td>\n",
       "      <td>0.638120</td>\n",
       "      <td>0.477090</td>\n",
       "      <td>-0.42852</td>\n",
       "      <td>-0.556410</td>\n",
       "      <td>-0.364000</td>\n",
       "      <td>-0.239380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080262</td>\n",
       "      <td>0.630030</td>\n",
       "      <td>0.321110</td>\n",
       "      <td>-0.467650</td>\n",
       "      <td>0.227860</td>\n",
       "      <td>0.360340</td>\n",
       "      <td>-0.378180</td>\n",
       "      <td>-0.566570</td>\n",
       "      <td>0.044691</td>\n",
       "      <td>0.303920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.301770</td>\n",
       "      <td>-0.16763</td>\n",
       "      <td>0.176840</td>\n",
       "      <td>0.317190</td>\n",
       "      <td>0.339730</td>\n",
       "      <td>-0.43478</td>\n",
       "      <td>-0.310860</td>\n",
       "      <td>-0.449990</td>\n",
       "      <td>-0.294860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>0.087939</td>\n",
       "      <td>-0.102850</td>\n",
       "      <td>-0.139310</td>\n",
       "      <td>0.223140</td>\n",
       "      <td>-0.080803</td>\n",
       "      <td>-0.356520</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>0.102160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.570880</td>\n",
       "      <td>-0.47160</td>\n",
       "      <td>0.180480</td>\n",
       "      <td>0.544490</td>\n",
       "      <td>0.726030</td>\n",
       "      <td>0.18157</td>\n",
       "      <td>-0.523930</td>\n",
       "      <td>0.103810</td>\n",
       "      <td>-0.175660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347270</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>0.075693</td>\n",
       "      <td>-0.062178</td>\n",
       "      <td>-0.389880</td>\n",
       "      <td>0.229020</td>\n",
       "      <td>-0.216170</td>\n",
       "      <td>-0.225620</td>\n",
       "      <td>-0.093918</td>\n",
       "      <td>-0.803750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.680470</td>\n",
       "      <td>-0.039263</td>\n",
       "      <td>0.30186</td>\n",
       "      <td>-0.177920</td>\n",
       "      <td>0.429620</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>-0.41376</td>\n",
       "      <td>0.132280</td>\n",
       "      <td>-0.298470</td>\n",
       "      <td>-0.085253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094375</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>-0.030880</td>\n",
       "      <td>-0.197220</td>\n",
       "      <td>0.082279</td>\n",
       "      <td>-0.094340</td>\n",
       "      <td>-0.073297</td>\n",
       "      <td>-0.064699</td>\n",
       "      <td>-0.260440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.268180</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>-0.27877</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.113840</td>\n",
       "      <td>0.699230</td>\n",
       "      <td>-0.51332</td>\n",
       "      <td>-0.473680</td>\n",
       "      <td>-0.330750</td>\n",
       "      <td>-0.138340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069043</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>0.251680</td>\n",
       "      <td>-0.245170</td>\n",
       "      <td>0.253810</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>-0.311780</td>\n",
       "      <td>-0.632100</td>\n",
       "      <td>-0.250280</td>\n",
       "      <td>-0.380970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.330420</td>\n",
       "      <td>0.249950</td>\n",
       "      <td>-0.60874</td>\n",
       "      <td>0.109230</td>\n",
       "      <td>0.036372</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>-0.55083</td>\n",
       "      <td>-0.074239</td>\n",
       "      <td>-0.092307</td>\n",
       "      <td>-0.328210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486090</td>\n",
       "      <td>-0.008027</td>\n",
       "      <td>0.031184</td>\n",
       "      <td>-0.365760</td>\n",
       "      <td>-0.426990</td>\n",
       "      <td>0.421640</td>\n",
       "      <td>-0.116660</td>\n",
       "      <td>-0.507030</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>-0.532850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.217050</td>\n",
       "      <td>0.465150</td>\n",
       "      <td>-0.46757</td>\n",
       "      <td>0.100820</td>\n",
       "      <td>1.013500</td>\n",
       "      <td>0.748450</td>\n",
       "      <td>-0.53104</td>\n",
       "      <td>-0.262560</td>\n",
       "      <td>0.168120</td>\n",
       "      <td>0.131820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138130</td>\n",
       "      <td>0.369730</td>\n",
       "      <td>-0.642890</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>-0.039315</td>\n",
       "      <td>-0.260370</td>\n",
       "      <td>0.120170</td>\n",
       "      <td>-0.043782</td>\n",
       "      <td>0.410130</td>\n",
       "      <td>0.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.257690</td>\n",
       "      <td>0.456290</td>\n",
       "      <td>-0.76974</td>\n",
       "      <td>-0.376790</td>\n",
       "      <td>0.592720</td>\n",
       "      <td>-0.063527</td>\n",
       "      <td>0.20545</td>\n",
       "      <td>-0.573850</td>\n",
       "      <td>-0.290090</td>\n",
       "      <td>-0.136620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>-0.395430</td>\n",
       "      <td>-0.385150</td>\n",
       "      <td>-1.000200</td>\n",
       "      <td>0.087599</td>\n",
       "      <td>-0.310090</td>\n",
       "      <td>-0.346770</td>\n",
       "      <td>-0.314380</td>\n",
       "      <td>0.750040</td>\n",
       "      <td>0.970650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>0.237270</td>\n",
       "      <td>0.404780</td>\n",
       "      <td>-0.20547</td>\n",
       "      <td>0.588050</td>\n",
       "      <td>0.655330</td>\n",
       "      <td>0.328670</td>\n",
       "      <td>-0.81964</td>\n",
       "      <td>-0.232360</td>\n",
       "      <td>0.274280</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123420</td>\n",
       "      <td>0.659610</td>\n",
       "      <td>-0.518020</td>\n",
       "      <td>-0.829950</td>\n",
       "      <td>-0.082739</td>\n",
       "      <td>0.281550</td>\n",
       "      <td>-0.423000</td>\n",
       "      <td>-0.273780</td>\n",
       "      <td>-0.007901</td>\n",
       "      <td>-0.030231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1        2         3         4         5        6   \\\n",
       "the  0.418000  0.249680 -0.41242  0.121700  0.345270 -0.044457 -0.49688   \n",
       ",    0.013441  0.236820 -0.16899  0.409510  0.638120  0.477090 -0.42852   \n",
       ".    0.151640  0.301770 -0.16763  0.176840  0.317190  0.339730 -0.43478   \n",
       "of   0.708530  0.570880 -0.47160  0.180480  0.544490  0.726030  0.18157   \n",
       "to   0.680470 -0.039263  0.30186 -0.177920  0.429620  0.032246 -0.41376   \n",
       "and  0.268180  0.143460 -0.27877  0.016257  0.113840  0.699230 -0.51332   \n",
       "in   0.330420  0.249950 -0.60874  0.109230  0.036372  0.151000 -0.55083   \n",
       "a    0.217050  0.465150 -0.46757  0.100820  1.013500  0.748450 -0.53104   \n",
       "\"    0.257690  0.456290 -0.76974 -0.376790  0.592720 -0.063527  0.20545   \n",
       "'s   0.237270  0.404780 -0.20547  0.588050  0.655330  0.328670 -0.81964   \n",
       "\n",
       "           7         8         9   ...        40        41        42  \\\n",
       "the -0.178620 -0.000660 -0.656600  ... -0.298710 -0.157490 -0.347580   \n",
       ",   -0.556410 -0.364000 -0.239380  ... -0.080262  0.630030  0.321110   \n",
       ".   -0.310860 -0.449990 -0.294860  ... -0.000064  0.068987  0.087939   \n",
       "of  -0.523930  0.103810 -0.175660  ... -0.347270  0.284830  0.075693   \n",
       "to   0.132280 -0.298470 -0.085253  ... -0.094375  0.018324  0.210480   \n",
       "and -0.473680 -0.330750 -0.138340  ... -0.069043  0.368850  0.251680   \n",
       "in  -0.074239 -0.092307 -0.328210  ... -0.486090 -0.008027  0.031184   \n",
       "a   -0.262560  0.168120  0.131820  ...  0.138130  0.369730 -0.642890   \n",
       "\"   -0.573850 -0.290090 -0.136620  ...  0.030498 -0.395430 -0.385150   \n",
       "'s  -0.232360  0.274280  0.242650  ... -0.123420  0.659610 -0.518020   \n",
       "\n",
       "           43        44        45        46        47        48        49  \n",
       "the -0.045637 -0.442510  0.187850  0.002785 -0.184110 -0.115140 -0.785810  \n",
       ",   -0.467650  0.227860  0.360340 -0.378180 -0.566570  0.044691  0.303920  \n",
       ".   -0.102850 -0.139310  0.223140 -0.080803 -0.356520  0.016413  0.102160  \n",
       "of  -0.062178 -0.389880  0.229020 -0.216170 -0.225620 -0.093918 -0.803750  \n",
       "to  -0.030880 -0.197220  0.082279 -0.094340 -0.073297 -0.064699 -0.260440  \n",
       "and -0.245170  0.253810  0.136700 -0.311780 -0.632100 -0.250280 -0.380970  \n",
       "in  -0.365760 -0.426990  0.421640 -0.116660 -0.507030 -0.027273 -0.532850  \n",
       "a    0.024142 -0.039315 -0.260370  0.120170 -0.043782  0.410130  0.179600  \n",
       "\"   -1.000200  0.087599 -0.310090 -0.346770 -0.314380  0.750040  0.970650  \n",
       "'s  -0.829950 -0.082739  0.281550 -0.423000 -0.273780 -0.007901 -0.030231  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "\n",
    "embedding_df = [] \n",
    "index = []\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile('glove.6B.zip') as glovezip:\n",
    "    # Read the file with 50 dimensional embeddings\n",
    "    with glovezip.open('glove.6B.50d.txt') as glovefile:\n",
    "        # Read line by line\n",
    "        for li, line in enumerate(glovefile):\n",
    "            # Print progress\n",
    "            if (li+1)%10000==0: print('.',end='')\n",
    "                \n",
    "            # Get the word and the corresponding vector\n",
    "            line_tokens = line.decode('utf-8').split(' ')\n",
    "            word = line_tokens[0]\n",
    "            vector = [float(v) for v in line_tokens[1:]]\n",
    "            \n",
    "            assert len(vector)==50\n",
    "            index.append(word)\n",
    "            # Update the embedding matrix\n",
    "            embedding_df.append(np.array(vector))\n",
    "            \n",
    "            # If the first 50000 words being read, finish\n",
    "            if li >= vocabulary_size-1:\n",
    "                break\n",
    "\n",
    "embedding_df = pd.DataFrame(embedding_df, index=index)\n",
    "embedding_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow Variable and config\n",
    "\n",
    "Here we create a TensorFlow variable to store the embeddings we read above and save it to the disk. This is necessary for the visualization. Along with that we will save metadata, which has the labels for each embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape: (50000, 50)\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to save our model\n",
    "log_dir = 'embeddings'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Save the weights we want to analyse as a variable. \n",
    "embeddings = tf.Variable(embedding_df.values)\n",
    "print(f\"weights.shape: {embeddings.shape}\")\n",
    "\n",
    "# Create a checkpoint from embedding\n",
    "checkpoint = tf.train.Checkpoint(embedding=embeddings)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), 'w', encoding='utf-8') as f:\n",
    "    for w in embedding_df.index:\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the TensorBoard\n",
    "\n",
    "* cd into the `packt_nlp_tf2/Appendix` directory\n",
    "* Run `tensorboard --logdir embeddings`\n",
    "\n",
    "## Visualizing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = projector.ProjectorConfig()\n",
    "\n",
    "# You can add multiple embeddings. Here we add only one.\n",
    "embedding_config = config.embeddings.add()\n",
    "embedding_config.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "# Link this tensor to its metadata file (e.g. labels).\n",
    "embedding_config.metadata_path = 'metadata.tsv'\n",
    "\n",
    "# TensorBoard will read this file during startup.\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
